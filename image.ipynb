{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from data import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run data.ipynb\n",
    "# %run preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Capture frames every 0.1 seconds and save it to local storage\n",
    "def capture_frames():\n",
    "    # Open the first available camera device\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Set the width and height of the capture frame\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    # Set the desired frame rate (in milliseconds)\n",
    "    frame_rate = 100 # 0.1 sec = 100 milliseconds\n",
    "\n",
    "    # Specify the directory to save the captured frames\n",
    "    save_dir = 'captured_frames/2'\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Initialize the frame counter\n",
    "    frame_num = 0\n",
    "\n",
    "    while True:\n",
    "        # Read a new frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was successfully captured\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # Wait for the desired amount of time before capturing the next frame\n",
    "        cv2.waitKey(frame_rate)\n",
    "\n",
    "        # Save the frame as an image file\n",
    "        filename = os.path.join(save_dir, f'frame_{frame_num}.jpg')\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "        # Increment the frame counter\n",
    "        frame_num += 1\n",
    "\n",
    "        if frame_num >= 100:\n",
    "            break\n",
    "\n",
    "    # Release the camera and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# capture_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'captured_frames/'\n",
    "# path = 'Miniset/'\n",
    "\n",
    "images, labels = load_data(path, grayscale=False, rgb=False)\n",
    "size_in_bytes = sys.getsizeof(images)\n",
    "\n",
    "print(images.shape)\n",
    "print(\"Images_Size = \", convert_bytes(size_in_bytes))\n",
    "\n",
    "show_random_dataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess_images = get_preprocessed_set(images)\n",
    "\n",
    "print(\"New_Shape = \", preprocess_images.shape)\n",
    "show_random_dataset(preprocess_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Skin detection\n",
    "    * Decent performance\n",
    "    * Detecting fans as well\n",
    "'''\n",
    "\n",
    "# Open the first available camera device\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the width and height of the capture frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Define the lower and upper bounds of the skin color in HSV color space\n",
    "skin_lower = np.array([0, 20, 70], dtype=np.uint8)\n",
    "skin_upper = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully captured\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR color space to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask to filter out the skin color\n",
    "    mask = cv2.inRange(hsv, skin_lower, skin_upper)\n",
    "\n",
    "    # Apply the mask to the original frame\n",
    "    skin = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # Display the skin regions (optional)\n",
    "    cv2.imshow('skin', skin)\n",
    "\n",
    "    # Wait for user input to exit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Hand Detection using skin segmentation and contour-based hand-detection\n",
    "    * Decent performance on both\n",
    "    * Detecting fans as well\n",
    "    * Combines face as well if hands get close to the face\n",
    "'''\n",
    "\n",
    "# Open the first available camera device\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the width and height of the capture frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Define the lower and upper bounds of the skin color in HSV color space\n",
    "skin_lower = np.array([0, 20, 70], dtype=np.uint8)\n",
    "skin_upper = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# Define the kernel size for the morphological operations\n",
    "kernel_size = 5\n",
    "\n",
    "while True:\n",
    "    # Read a new frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully captured\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR color space to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask to filter out the skin color\n",
    "    mask = cv2.inRange(hsv, skin_lower, skin_upper)\n",
    "\n",
    "    # Apply morphological operations to remove noise and smooth the image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw a bounding box around the largest contour (assumed to be the hand)\n",
    "    if len(contours) > 0:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Wait for user input to exit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Another approach to detect hand while avoiding faces (using haarcascade)\n",
    "    * Detecting both hands\n",
    "    * Detecting face when hands not available or hands too close to face\n",
    "    * Detecting fans\n",
    "'''\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Define the lower and upper bounds of the skin color in HSV color space\n",
    "skin_lower = np.array([0, 20, 70], dtype=np.uint8)\n",
    "skin_upper = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# Define the kernel size for the morphological operations\n",
    "kernel_size = 5\n",
    "\n",
    "# Open the first available camera device\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully captured\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR color space to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask to filter out the skin color\n",
    "    mask = cv2.inRange(hsv, skin_lower, skin_upper)\n",
    "\n",
    "    # Apply morphological operations to remove noise and smooth the image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Remove the face region from the binary image\n",
    "    for (x, y, w, h) in faces:\n",
    "        mask[y:y+h, x:x+w] = 0\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw a bounding box around the largest contour (assumed to be the hand)\n",
    "    if len(contours) > 0:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Wait for user input to exit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand detection using mediapipe hand tracking module\n",
    "\n",
    "\n",
    "# import mediapipe as mp\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the Mediapipe hand tracking module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to RGB format for use with Mediapipe\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with Mediapipe to detect hands\n",
    "    results = hands.process(frame)\n",
    "\n",
    "    # If hands were detected, extract the hand landmarks and draw them on the frame\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Extract the hand landmarks as a list of (x,y,z) tuples\n",
    "            landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n",
    "\n",
    "            # Draw a circle at each landmark location\n",
    "            for lm in landmarks:\n",
    "                x, y, z = lm\n",
    "                cv2.circle(frame, (int(x*frame.shape[1]), int(y*frame.shape[0])), radius=5, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Wait for a key press and check if the 'q' key was pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
