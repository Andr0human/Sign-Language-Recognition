{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test saved models with real-time camera test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libs\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import math\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Indian Sign Language model\n",
    "# model = load_model('isl_model.h5')\n",
    "isl_model = load_model('isl_model.h5')\n",
    "\n",
    "isl_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_names = [chr(i + 65) for i in range(26)]\n",
    "\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=2)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(class_names)\n",
    "\n",
    "# PreProcess the image before classification\n",
    "def preprocess_image(frame):\n",
    "\n",
    "    hands, _ = detector.findHands(frame)\n",
    "\n",
    "    if len(hands) == 0:\n",
    "        return None\n",
    "\n",
    "    lmlist = hands[0]['lmList']\n",
    "    center = hands[0]['center']\n",
    "    bbox = hands[0]['bbox']\n",
    "    _, _, W, H = bbox\n",
    "\n",
    "    data = tuple((x - center[0], y - center[1]) for x, y, _ in lmlist)\n",
    "\n",
    "    min_x = min(tuple(x for x, _ in data))\n",
    "    min_y = min(tuple(y for _, y in data))\n",
    "\n",
    "    data = tuple((x - min_x, y - min_y) for x, y in data)\n",
    "\n",
    "    # Note: Instead of dividing x by w and y by H, an alterative\n",
    "    #       approach could be divide x and y by sqrt(w*w + h*h) [TO TRY]\n",
    "    data = tuple((round((x / W), 3) , round((y / H), 3)) for x, y in data)\n",
    "\n",
    "    return np.array(tuple(val for pair in data for val in pair))\n",
    "\n",
    "\n",
    "# Makes prediction from the data using provided model\n",
    "def make_prediction(model, data):\n",
    "\n",
    "    prediction = model.predict(data[np.newaxis, ...])\n",
    "    prediction_p = tf.nn.softmax(prediction)\n",
    "    yhat = np.argmax(prediction_p)\n",
    "\n",
    "    return str(label_encoder.inverse_transform([yhat]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Function to predict the sign from webcam input\n",
    "def predict_sign(model, image_preprocessor):\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is False:\n",
    "            raise('Error in Frame Capture!')\n",
    "\n",
    "        # Generate data from frame to be paased from model input\n",
    "        data = image_preprocessor(frame)\n",
    "\n",
    "        if data is None:\n",
    "            sign = 'XXX'\n",
    "        else:\n",
    "            # Make prediction using the model and data from the frame\n",
    "            sign = make_prediction(model, data)\n",
    "\n",
    "        # Display the predicted sign label on the screen\n",
    "        cv2.putText(frame, sign, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Indian Sign Language Recognition', frame)\n",
    "\n",
    "        # Stop the program when the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function to start predicting signs from webcam input\n",
    "predict_sign(model=isl_model, image_preprocessor=preprocess_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa6e12f5e5ac0ef8d4fc5ed68460255f96e78ccc6ae90f782d559be177fce646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
